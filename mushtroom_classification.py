# -*- coding: utf-8 -*-
"""Mushtroom_Classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1TDfviHWh-595g5G8UHA8fCr2h_VI8U9v
"""

from google.colab import files
files.upload()

!mkdir ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

!cp kaggle.json ~/.kaggle/

!chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets download -d maysee/mushrooms-classification-common-genuss-images

!unzip -qq archive.zip

!unzip -qq mushrooms-classification-common-genuss-images.zip

import os, random, shutil, pathlib
from IPython.display import clear_output
from tensorflow.keras.utils import image_dataset_from_directory
from matplotlib import pyplot as plt
from tensorflow import keras
from tensorflow.keras import layers
import tensorflow_hub as hub
import tensorflow as tf
import numpy as np

original_dir = pathlib.Path('/content/Mushrooms')
new_base_dir = pathlib.Path('/kaggle/working/Mushrooms')
class_names = os.listdir('/content/Mushrooms')

BATCH_SIZE = 32
IMG_SIZE = (224, 224)
EPOCHS = 100
PRETRAINED_MODEL_PATH = 'https://kaggle.com/models/google/resnet-v2/frameworks/TensorFlow2/variations/50-classification/versions/2'

# Copy 300 random images from each class to working directory
for mushroom in class_names:
    dir = new_base_dir / mushroom
    os.makedirs(dir, exist_ok=True)
    fnames = random.sample(os.listdir(original_dir / mushroom), k=300)
    for fname in fnames:
        shutil.copyfile(src=original_dir / mushroom / fname,
                       dst=dir / fname)

train_ds = image_dataset_from_directory(
    new_base_dir,
    labels='inferred',
    label_mode='categorical',
    class_names=class_names,
    color_mode='rgb',
    batch_size=BATCH_SIZE,
    image_size=IMG_SIZE,
    shuffle=True,
    seed=33,
    validation_split=0.1,
    subset='training',
    interpolation='nearest')

val_ds = image_dataset_from_directory(
    new_base_dir,
    labels='inferred',
    label_mode='categorical',
    class_names=class_names,
    color_mode='rgb',
    batch_size=BATCH_SIZE,
    image_size=IMG_SIZE,
    shuffle=False,
    seed=33,
    validation_split=0.1,
    subset='validation',
    interpolation='nearest')

data_augmentation = keras.Sequential(
[
    layers.RandomFlip('horizontal'),
    layers.RandomRotation(0.1),
    layers.RandomZoom(0.2),
    layers.Rescaling(1/255.)
])

normalization = layers.Rescaling(1/255.)

training_data = train_ds.map(lambda x,y: (data_augmentation(x), y)).prefetch(1).cache()
validation_data = val_ds.map(lambda x,y: (normalization(x), y)).prefetch(1).cache()

keras_layer = hub.KerasLayer(PRETRAINED_MODEL_PATH)
rmsprop = tf.keras.optimizers.RMSprop(learning_rate=0.0001)

callbacks = [
    tf.keras.callbacks.ModelCheckpoint(
    filepath='weights.ckpt',
    save_best_only=True,
    save_weights_only=True,
    monitor='val_loss')
]

inputs = layers.Input(shape=IMG_SIZE + (3,))
x = keras_layer(inputs)
x = tf.keras.layers.Dense(224, activation='relu')(x)
x = tf.keras.layers.Dropout(0.5)(x)
outputs = layers.Dense(len(class_names), activation='softmax')(x)

model = keras.Model(inputs, outputs)
model.summary()

model.compile(loss='categorical_crossentropy',
             optimizer=rmsprop,
             metrics=['accuracy'])

history = model.fit(training_data, epochs=EPOCHS, validation_data=validation_data, callbacks=callbacks)

inputs = layers.Input(shape=IMG_SIZE + (3,))
x = keras_layer(inputs)
x = tf.keras.layers.Dense(224, activation='relu')(x)
x = tf.keras.layers.Dropout(0.5)(x)
outputs = layers.Dense(len(class_names), activation='softmax')(x)

resnet50 = keras.Model(inputs, outputs)

resnet50.compile(loss='categorical_crossentropy',
             optimizer=rmsprop,
             metrics=['accuracy'])

resnet50.load_weights('/content/weights.ckpt')
resnet50.save('/kaggle/working/Model')

clear_output()

!kaggle kernels output encode0/mushrooms-classification-with-tensorflow -p /path/to/dest

model_checkpoint_path: "weights.ckpt"
all_model_checkpoint_paths: "weights.ckpt"

inputs = layers.Input(shape=IMG_SIZE + (3,))
x = keras_layer(inputs)
x = tf.keras.layers.Dense(224, activation='relu')(x)
x = tf.keras.layers.Dropout(0.5)(x)
outputs = layers.Dense(len(class_nams), activation='softmax')(x)
e
resnet50 = keras.Model(inputs, outputs)

resnet50.compile(loss='categorical_crossentropy',
             optimizer=rmsprop,
             metrics=['accuracy'])

resnet50.load_weights('/content/weights.ckpt')
resnet50.save('/kaggle/working/Model')

clear_output()